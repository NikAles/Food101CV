{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0207e75e",
   "metadata": {},
   "source": [
    "#### Библиотеки, девайс и функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04d50ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import models\n",
    "from torchinfo import summary\n",
    "from torchvision.datasets import Food101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ab18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda import is_available\n",
    "device = \"cuda\" if is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bc6ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(train_data, test_data, batch_size, num_workers):\n",
    "\n",
    "    #train_data = torchvision.datasets.ImageFolder(root=train_dir_path, transform=trans)\n",
    "    #test_data = torchvision.datasets.ImageFolder(root=test_dir_path, transform=trans)\n",
    "\n",
    "    train_dataloader = DataLoader(dataset=train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=num_workers)\n",
    "    test_dataloader = DataLoader(dataset=test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=num_workers)\n",
    "    classes_names = train_data.classes\n",
    "\n",
    "    return train_dataloader, test_dataloader, classes_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4009aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct/len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1444c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(train_loss_values, train_acc_values, test_loss_values, test_acc_values, train_epoch_count, test_epoch_count):\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(train_epoch_count, train_acc_values, c='g', label='Train Acc')\n",
    "    plt.plot(train_epoch_count, test_acc_values, c='r', label='Test ACC')\n",
    "    plt.title('Acc')\n",
    "    plt.legend()\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(train_epoch_count, train_loss_values, c='blue', label=\"Train Loss\")\n",
    "    plt.plot(train_epoch_count, test_loss_values, c='orange', label=\"Test Loss\")\n",
    "    plt.title('Loss')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143628fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, MODEL_PATH, model_name):\n",
    "    SAVE_PATH = MODEL_PATH / model_name\n",
    "    torch.save(obj = model.state_dict(),\n",
    "               f = SAVE_PATH)\n",
    "    print(f\"Saved to: {SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e41d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, test_dataloader, loss_fn, optimizer, accuracy_fn, epochs, device):\n",
    "    train_epoch_count = []\n",
    "    train_loss_values = []\n",
    "    train_acc_values = []\n",
    "    test_epoch_count = []\n",
    "    test_loss_values = []\n",
    "    test_acc_values = []\n",
    "    #epochs = 10\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Train Block\n",
    "        ls_loss = 0\n",
    "        ls_acc = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for batch, (X, y) in enumerate(train_dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            #y = y.type(torch.long)\n",
    "\n",
    "            logits = model(X).squeeze()\n",
    "            preds = torch.argmax(torch.softmax(logits, dim=1),dim=1)\n",
    "            #print(X.shape, y.shape, logits.shape)\n",
    "            loss = loss_fn(logits, y)\n",
    "            acc = accuracy_fn(y_true = y, y_pred = preds)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            ls_loss += loss.item()\n",
    "            ls_acc += acc\n",
    "            if batch % 400 == 0:\n",
    "                print(f\"Epoch: {epoch+1} | Batch: {batch}...\")\n",
    "        mean_loss = ls_loss / len(train_dataloader)\n",
    "        mean_acc = ls_acc / len(train_dataloader)\n",
    "        train_loss_values.append(loss.item())\n",
    "        train_acc_values.append(acc)\n",
    "        train_epoch_count.append(epoch+1)\n",
    "        print(f\"Epoch: {epoch+1} | Loss: {mean_loss:.4f} | Acc: {mean_acc:.2f}%\")\n",
    "\n",
    "\n",
    "        # Test Block\n",
    "        ls_loss, ls_acc = 0, 0\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for batch, (X, y) in enumerate(test_dataloader):\n",
    "            with torch.inference_mode():\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                #y = y.type(torch.long)\n",
    "                mean_loss, mean_acc = 0, 0\n",
    "                logits = model(X).squeeze()\n",
    "                preds = torch.argmax(torch.softmax(logits, dim=1),dim=1)\n",
    "                loss = loss_fn(logits, y)\n",
    "                acc = accuracy_fn(y_true = y,y_pred = preds)\n",
    "                ls_loss += loss.item()\n",
    "                ls_acc += acc\n",
    "                if batch % 300 == 0:\n",
    "                    print(f\"TEST :    Epoch: {epoch+1} | Batch: {batch}...\")\n",
    "        mean_loss = ls_loss / len(test_dataloader)\n",
    "        mean_acc = ls_acc / len(test_dataloader)\n",
    "        test_loss_values.append(loss.item())\n",
    "        test_acc_values.append(acc)\n",
    "        test_epoch_count.append(epoch+1)\n",
    "        print(f\"TEST :    Epoch: {epoch+1} | Loss: {mean_loss:.4f} | Acc: {mean_acc:.2f}%\\n\\n\")\n",
    "    return train_loss_values, train_acc_values, test_loss_values, test_acc_values, train_epoch_count, test_epoch_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e8abd2",
   "metadata": {},
   "source": [
    "# ViT_b_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0072a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# получение весов модели и трансформации модели\n",
    "ViT_b_16_weights = models.ViT_B_16_Weights.DEFAULT\n",
    "auto_transform = ViT_b_16_weights.transforms()\n",
    "# получение датасета с транформацией\n",
    "train_data = Food101(root=\"data/train\",\n",
    "                     split=\"train\",\n",
    "                     download=True,\n",
    "                     transform=                  auto_transform)\n",
    "test_data = Food101(root=\"data/test\",\n",
    "                     split=\"test\",\n",
    "                     download=True,\n",
    "                     transform=                  auto_transform)\n",
    "\n",
    "cpu_c = os.cpu_count()\n",
    "BATCH_SIZE = 32\n",
    "# получение даталоадеров и списка классов\n",
    "train_dataloader, test_dataloader, classes_names = make_data(train_data, test_data, batch_size=BATCH_SIZE, num_workers=cpu_c)\n",
    "train_dataloader, test_dataloader, classes_names[:10], auto_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bfc0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ViT_b_16 = models.vit_b_16(weights=ViT_b_16_weights).to(device)\n",
    "auto_transform = ViT_b_16.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd93c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ViT_b_16.heads.head = nn.Linear(in_features=768, out_features=101, bias=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfa8d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model=ViT_b_16,input_size=(32, 3, 224, 224),col_names=['input_size', 'output_size',\"num_params\", 'trainable'],col_width=20,row_settings=['var_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d1c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in ViT_b_16.parameters():\n",
    "        params.requires_grad=False\n",
    "\n",
    "for params in ViT_b_16.heads.parameters():\n",
    "        params.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef16cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model=ViT_b_16,input_size=(32, 3, 224, 224),col_names=['input_size', 'output_size',\"num_params\", 'trainable'],col_width=20,row_settings=['var_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59751be",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(ViT_b_16.parameters(),\n",
    "                              lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loss_values_ViT_b_16, train_acc_values_ViT_b_16, test_loss_values_ViT_b_16, test_acc_values_ViT_b_16, train_epoch_count_ViT_b_16, test_epoch_count_ViT_b_16 = train_model(\n",
    "    model=ViT_b_16, train_dataloader=train_dataloader, test_dataloader=test_dataloader,\n",
    "            optimizer=optimizer, loss_fn=loss_fn ,accuracy_fn=accuracy_fn, epochs=20, device=device)\n",
    "\n",
    "plots(train_loss_values_ViT_b_16, train_acc_values_ViT_b_16, test_loss_values_ViT_b_16, test_acc_values_ViT_b_16, train_epoch_count_ViT_b_16, test_epoch_count_ViT_b_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f9f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH_vIT_AFTER_5EPOCHS = Path(\"/models\")\n",
    "MODEL_NAME_vIT_AFTER_5EPOCHS = \"second_model_TiV_16_b.pth\"\n",
    "MODEL_PATH_vIT_AFTER_5EPOCHS / MODEL_NAME_vIT_AFTER_5EPOCHS\n",
    "save_model(ViT_b_16, MODEL_PATH_vIT_AFTER_5EPOCHS, MODEL_NAME_vIT_AFTER_5EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
